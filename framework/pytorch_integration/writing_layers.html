

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Writing TC operations &mdash; Tensor Comprehensions v0.1.1 documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/tc_theme.css" type="text/css" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Autograd with TC" href="autograd_with_tc.html" />
    <link rel="prev" title="Python API" href="python_api.html" /> 

  
  <script src="../../_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="../../index.html">
          

          
            
            <img src="../../_static/tc-logo-full-color-with-text-2.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                v0.1.1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Index</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../introduction.html">What is Tensor Comprehensions?</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../introduction.html#example-of-using-tc-with-framework">Example of using TC with framework</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../introduction.html#tensor-comprehension-notation">Tensor Comprehension Notation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../introduction.html#examples-of-tc">Examples of TC</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../introduction.html#simple-matrix-vector">Simple matrix-vector</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../introduction.html#simple-2-d-convolution-no-stride-no-padding">Simple 2-D convolution (no stride, no padding)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../introduction.html#simple-2d-max-pooling">Simple 2D max pooling</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../semantics.html">Semantics</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../semantics.html#types">Types</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../semantics.html#data-layout">Data Layout</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../semantics.html#variable-scoping">Variable Scoping</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../semantics.html#implied-reductions-and-operators">Implied Reductions and operators</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../semantics.html#size-expressions">Size Expressions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../semantics.html#statements">Statements</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../semantics.html#expressions">Expressions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../semantics.html#grammar">Grammar</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../inference.html">Range Inference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../inference.html#the-range-inference-algorithm">The Range Inference Algorithm</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../inference.html#preconditions">Preconditions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../inference.html#worked-examples">Worked Examples</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../inference.html#inverted-indexing">Inverted indexing</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../inference.html#strided-indexing-with-constant-stride">Strided indexing with constant stride</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../inference.html#strided-indexing-with-offsets">Strided indexing with offsets</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../inference.html#strided-indexing-with-dynamic-stride">Strided indexing with dynamic stride</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../inference.html#constant-fill-using-an-exists-clause">Constant fill using an exists clause</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../halide_integration.html">Relation to Halide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../halide_integration.html#use-of-halide-in-tc">Use of Halide in TC</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../mapping_options.html">Mapping Options</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../mapping_options.html#how-to-choose-starting-mapping-options">How to choose starting mapping options?</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../mapping_options.html#options-api">Options API</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../mapping_options.html#defaults-provided">Defaults provided</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../mapping_options.html#available-options">Available options</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../mapping_options.html#impact-on-performance">Impact on Performance</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../mapping_options.html#possible-compiler-issues">Possible compiler issues</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../autotuner.html">Autotuner</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../autotuner.html#parameters-for-autotuning">Parameters for Autotuning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../autotuner.html#caching">Caching</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../performance.html">Performance of TC</a></li>
</ul>
<p class="caption"><span class="caption-text">Machine Learning with TC</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../ml_with_tc.html">Positioning of TC in ML Software stacks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../ml_with_tc.html#implications-of-ml-framework-integration">Implications of ML Framework Integration</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../ml_with_tc.html#one-tc-function-one-kernel">One TC function one kernel</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../ml_with_tc.html#no-variable-allocations">No Variable Allocations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../ml_with_tc.html#graph-level">Graph Level</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../ml_with_tc.html#minimal-information-to-write-ml-layers-concisely">Minimal information to write ML layers concisely</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../ml_with_tc.html#c-style-loops">C-style loops</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../ml_with_tc.html#halide">Halide</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../ml_with_tc.html#tc">TC</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../ml_with_tc.html#matrix-languages">Matrix Languages</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../integrating_any_ml_framework.html">Integrating TC with ML framework</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../integrating_any_ml_framework.html#step-1-dlpack-support-in-framework">Step 1: DLpack support in framework</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../integrating_any_ml_framework.html#step-2-integrating-tc">Step 2: Integrating TC</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../coding_conventions.html">Coding Conventions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../coding_conventions.html#use-indices-named-after-parameters">Use indices named after parameters</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../coding_conventions.html#prefix-reduction-index-names-with-r">Prefix reduction index names with <code class="code docutils literal notranslate"><span class="pre">r_</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../coding_conventions.html#filter-non-rectangular-regions-with-data-dependencies">Filter non-rectangular regions with data-dependencies</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../coding_conventions.html#prefix-gradient-tensors-names-with-d">Prefix gradient tensors names with <code class="code docutils literal notranslate"><span class="pre">d_</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../coding_conventions.html#a-more-complex-example">A more complex example</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">PyTorch Integration</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="getting_started.html">Getting Started</a><ul>
<li class="toctree-l2"><a class="reference internal" href="getting_started.html#installation">Installation</a></li>
<li class="toctree-l2"><a class="reference internal" href="getting_started.html#example">Example</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="python_api.html">Python API</a><ul>
<li class="toctree-l2"><a class="reference internal" href="python_api.html#high-level-api">High-level API</a></li>
<li class="toctree-l2"><a class="reference internal" href="python_api.html#low-level-api">Low-level API</a></li>
<li class="toctree-l2"><a class="reference internal" href="python_api.html#caching-and-configuration">Caching and Configuration</a></li>
</ul>
</li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Writing TC operations</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#example">Example</a></li>
<li class="toctree-l2"><a class="reference internal" href="#specifying-mappingoptions">Specifying MappingOptions</a></li>
<li class="toctree-l2"><a class="reference internal" href="#loading-from-cache">Loading from cache</a></li>
<li class="toctree-l2"><a class="reference internal" href="#autotuning">Autotuning</a></li>
<li class="toctree-l2"><a class="reference internal" href="#fixed-tc-varying-input-sizes">Fixed TC, varying input sizes</a></li>
<li class="toctree-l2"><a class="reference internal" href="#pseudo-templating">Pseudo-templating</a></li>
<li class="toctree-l2"><a class="reference internal" href="#built-in-functions">Built-in Functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="#more-examples">More examples</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="autograd_with_tc.html">Autograd with TC</a></li>
<li class="toctree-l1"><a class="reference internal" href="debugging.html">Debugging</a><ul>
<li class="toctree-l2"><a class="reference internal" href="debugging.html#example-usage">Example usage</a></li>
<li class="toctree-l2"><a class="reference internal" href="debugging.html#printing-tc-generated-cuda-code">Printing TC generated CUDA code</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="frequently_asked_questions.html">Frequently Asked Questions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="frequently_asked_questions.html#tc-language">TC language</a><ul>
<li class="toctree-l3"><a class="reference internal" href="frequently_asked_questions.html#how-are-temporary-variables-handled-in-tc">How are temporary variables handled in TC?</a></li>
<li class="toctree-l3"><a class="reference internal" href="frequently_asked_questions.html#can-i-re-use-a-temporary-variable">Can I re-use a temporary variable?</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="frequently_asked_questions.html#autotuner">Autotuner</a><ul>
<li class="toctree-l3"><a class="reference internal" href="frequently_asked_questions.html#at-the-start-of-a-new-generation-i-see-higher-kernel-runtimes-why">At the start of a new generation, I see higher kernel runtimes, Why?</a></li>
<li class="toctree-l3"><a class="reference internal" href="frequently_asked_questions.html#i-sometimes-see-fluctuations-in-the-best-kernel-time-why">I sometimes see fluctuations in the best kernel time, why?</a></li>
<li class="toctree-l3"><a class="reference internal" href="frequently_asked_questions.html#how-do-i-stop-autotuning-early-and-save-cache">How do I stop autotuning early and save cache?</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Installation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../installation.html">Installation Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../installation.html#conda-installation">Conda installation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../installation.html#build-from-source">Build from source</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../installation.html#prerequisites">Prerequisites</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../installation.html#conda-from-scratch-first-time-configuration">Conda from scratch (first time configuration)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../installation.html#activate-conda-in-your-current-terminal">Activate conda in your current terminal</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../installation.html#build-tc-with-dependencies-supplied-by-conda">Build TC with dependencies supplied by conda</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../installation.html#test-locally">Test locally</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../installation.html#advanced-development-mode-installation">Advanced / development mode installation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="../../installation.html#optional-dependencies">Optional dependencies</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../installation.html#cudnn-version-7-1-in-caffe2-dev-mode">Cudnn version 7.1 in Caffe2 / dev mode</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../installation_colab_research.html">Installation in the Google Colaboratory environment</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../installation_colab_research.html#step-1-create-new-notebook-in-the-google-research-colaboratory">Step 1: Create new Notebook in the Google Research Colaboratory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../installation_colab_research.html#step-2-create-a-new-code-cell-with-the-following-code">Step 2: Create a new Code Cell, with the following code</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../installation_colab_research.html#step-3-use-tc-normally-from-python-torch-environment">Step 3: Use TC normally, from Python/Torch environment</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Paper</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../report.html">Tech Report</a></li>
</ul>
<p class="caption"><span class="caption-text">Support</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../contacts.html">Contacts</a><ul>
<li class="toctree-l2"><a class="reference internal" href="../../contacts.html#bugs-and-features">Bugs and features</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../contacts.html#mailing-list">Mailing list</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../contacts.html#contributions">Contributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../contacts.html#slack-channel">Slack channel</a></li>
</ul>
</li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Tensor Comprehensions</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> &raquo;</li>
        
      <li>Writing TC operations</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../_sources/framework/pytorch_integration/writing_layers.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="module-tensor_comprehensions">
<span id="writing-tc-operations"></span><h1>Writing TC operations<a class="headerlink" href="#module-tensor_comprehensions" title="Permalink to this headline">¶</a></h1>
<p>This document focuses on writing TC operations using the high-level API.
For examples of using the low-level API, see the Python API documentation.</p>
<p>To create a CUDA kernel implementing an operation backed by TC, one should:</p>
<ol class="arabic simple">
<li>Create a callable TC object by calling <a class="reference internal" href="python_api.html#tensor_comprehensions.define" title="tensor_comprehensions.define"><code class="xref py py-func docutils literal notranslate"><span class="pre">define()</span></code></a></li>
<li>Create input PyTorch Tensors</li>
<li>Call the TC object with the input PyTorch Tensors</li>
</ol>
<p>When running, the backend ensures the TC is compiled and memoized for the
given input tensor sizes (see the documentation for <a class="reference internal" href="python_api.html#tensor_comprehensions.define" title="tensor_comprehensions.define"><code class="xref py py-func docutils literal notranslate"><span class="pre">define()</span></code></a> for more details).
Calling the object returned by <a class="reference internal" href="python_api.html#tensor_comprehensions.define" title="tensor_comprehensions.define"><code class="xref py py-func docutils literal notranslate"><span class="pre">define()</span></code></a> executes the
corresponding operation and returns a list of outputs.
If the operation has already been compiled, in the following runs, the TC
backend will reuse the memoized compilation result and run the operation
directly.</p>
<div class="section" id="example">
<h2>Example<a class="headerlink" href="#example" title="Permalink to this headline">¶</a></h2>
<p>The following example demonstrates the steps above.
We use the <a class="reference internal" href="python_api.html#tensor_comprehensions.make_naive_options_factory" title="tensor_comprehensions.make_naive_options_factory"><code class="xref py py-func docutils literal notranslate"><span class="pre">make_naive_options_factory()</span></code></a> builder function to provide
naive <a class="reference internal" href="python_api.html#tensor_comprehensions.tclib.MappingOptions" title="tensor_comprehensions.tclib.MappingOptions"><code class="xref py py-class docutils literal notranslate"><span class="pre">MappingOptions</span></code></a>.  Naive options result in poor performance.
At this time, there is no notion of a default <a class="reference internal" href="python_api.html#tensor_comprehensions.tclib.MappingOptions" title="tensor_comprehensions.tclib.MappingOptions"><code class="xref py py-class docutils literal notranslate"><span class="pre">MappingOptions</span></code></a>.
Instead one should use the autotuner to perform an evolutionary search
starting from an initial <a class="reference internal" href="python_api.html#tensor_comprehensions.tclib.MappingOptions" title="tensor_comprehensions.tclib.MappingOptions"><code class="xref py py-class docutils literal notranslate"><span class="pre">MappingOptions</span></code></a> object and return a better
<a class="reference internal" href="python_api.html#tensor_comprehensions.tclib.MappingOptions" title="tensor_comprehensions.tclib.MappingOptions"><code class="xref py py-class docutils literal notranslate"><span class="pre">MappingOptions</span></code></a> object for a given TC function and sizes (more on this
below).</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">tensor_comprehensions</span> <span class="kn">as</span> <span class="nn">tc</span>
<span class="n">T</span> <span class="o">=</span> <span class="n">tc</span><span class="o">.</span><span class="n">define</span><span class="p">(</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    def add(float(N) A, float(N) B) -&gt; (C) { C(i) = A(i) + B(i) }</span>
<span class="sd">    def sub(float(N) A, float(N) B) -&gt; (C) { C(i) = A(i) - B(i) }</span>
<span class="sd">    &quot;&quot;&quot;</span><span class="p">,</span>
    <span class="n">tc</span><span class="o">.</span><span class="n">make_naive_options_factory</span><span class="p">())</span>
<span class="n">A</span><span class="p">,</span> <span class="n">B</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda&#39;</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda&#39;</span><span class="p">)</span>
<span class="n">C</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">)</span>
<span class="n">tc</span><span class="o">.</span><span class="n">assert_almost_equal</span><span class="p">(</span><span class="n">C</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">),</span> <span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">)</span>
<span class="n">D</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">)</span>
<span class="n">tc</span><span class="o">.</span><span class="n">assert_almost_equal</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="p">(</span><span class="n">A</span> <span class="o">-</span> <span class="n">B</span><span class="p">),</span> <span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
</div>
<div class="section" id="specifying-mappingoptions">
<h2>Specifying MappingOptions<a class="headerlink" href="#specifying-mappingoptions" title="Permalink to this headline">¶</a></h2>
<p>There are three ways to construct <a class="reference internal" href="python_api.html#tensor_comprehensions.tclib.MappingOptions" title="tensor_comprehensions.tclib.MappingOptions"><code class="xref py py-class docutils literal notranslate"><span class="pre">MappingOptions</span></code></a> when defining a TC:</p>
<ul class="simple">
<li><strong>Naive MappingOptions</strong>:<ul>
<li><code class="code docutils literal notranslate"><span class="pre">naive</span></code>: this is provided to create a basic GPU mapping strategy with
3-D tiling by 32x32x32, mapping to 256x256 blocks 32x8 threads. This
should by no means be considered a good baseline but just a point to
get started using TC. Once a correct TC is written, we recommend either
using options loaded from a <a class="reference internal" href="python_api.html#tensor_comprehensions.tclib.MappingOptionsCache" title="tensor_comprehensions.tclib.MappingOptionsCache"><code class="xref py py-class docutils literal notranslate"><span class="pre">MappingOptionsCache</span></code></a> or resulting from
a tuning run. One can also modify a <a class="reference internal" href="python_api.html#tensor_comprehensions.tclib.MappingOptions" title="tensor_comprehensions.tclib.MappingOptions"><code class="xref py py-class docutils literal notranslate"><span class="pre">MappingOptions</span></code></a> object
programmatically (see the API documentation).</li>
</ul>
</li>
<li><strong>Loading from MappingOptionsCache</strong>: a <a class="reference internal" href="python_api.html#tensor_comprehensions.tclib.MappingOptionsCache" title="tensor_comprehensions.tclib.MappingOptionsCache"><code class="xref py py-class docutils literal notranslate"><span class="pre">MappingOptionsCache</span></code></a> provides
a simple interface to load the best options from a previous tuning run.</li>
<li><strong>Autotuning</strong>: A kernel can be autotuned for fixed input tensor sizes.
Optionally the best performing options can be cached to a file and reused to
compile and run a TC operation.</li>
</ul>
</div>
<div class="section" id="loading-from-cache">
<h2>Loading from cache<a class="headerlink" href="#loading-from-cache" title="Permalink to this headline">¶</a></h2>
<p>Loading the best options from a previously serialized <a class="reference internal" href="python_api.html#tensor_comprehensions.tclib.MappingOptionsCache" title="tensor_comprehensions.tclib.MappingOptionsCache"><code class="xref py py-class docutils literal notranslate"><span class="pre">MappingOptionsCache</span></code></a>
can be achieved by making a factory function with
<a class="reference internal" href="python_api.html#tensor_comprehensions.make_load_from_cache_options_factory" title="tensor_comprehensions.make_load_from_cache_options_factory"><code class="xref py py-func docutils literal notranslate"><span class="pre">make_load_from_cache_options_factory()</span></code></a> and passing it as an argument to the
<a class="reference internal" href="python_api.html#tensor_comprehensions.define" title="tensor_comprehensions.define"><code class="xref py py-func docutils literal notranslate"><span class="pre">define()</span></code></a> function:</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">group_normalization</span><span class="o">=</span><span class="s2">&quot;&quot;&quot;...&quot;&quot;&quot;</span>
<span class="n">N</span><span class="p">,</span> <span class="n">G</span><span class="p">,</span> <span class="n">D</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">56</span><span class="p">,</span> <span class="mi">56</span>
<span class="n">T</span> <span class="o">=</span> <span class="n">tc</span><span class="o">.</span><span class="n">define</span><span class="p">(</span>
    <span class="n">group_normalization</span><span class="p">,</span>
    <span class="n">tc</span><span class="o">.</span><span class="n">make_load_from_cache_options_factory</span><span class="p">(</span><span class="s1">&#39;some_file_path&#39;</span><span class="p">))</span>
<span class="n">I</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">beta</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">G</span><span class="p">,</span> <span class="n">D</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda&#39;</span><span class="p">),</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">D</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda&#39;</span><span class="p">),</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">D</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda&#39;</span><span class="p">))</span>
<span class="n">Sum</span><span class="p">,</span> <span class="n">SumSq</span><span class="p">,</span> <span class="n">O</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">group_normalization</span><span class="p">(</span><span class="n">I</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
<p>One can also use the low-level <a class="reference internal" href="python_api.html#tensor_comprehensions.tclib.MappingOptionsCache" title="tensor_comprehensions.tclib.MappingOptionsCache"><code class="xref py py-class docutils literal notranslate"><span class="pre">MappingOptionsCache</span></code></a>.</p>
</div>
<div class="section" id="autotuning">
<h2>Autotuning<a class="headerlink" href="#autotuning" title="Permalink to this headline">¶</a></h2>
<p>Tuning can be achieved by making a factory function with
<a class="reference internal" href="python_api.html#tensor_comprehensions.make_autotuned_options_factory" title="tensor_comprehensions.make_autotuned_options_factory"><code class="xref py py-func docutils literal notranslate"><span class="pre">make_autotuned_options_factory()</span></code></a> and passing it as an argument to the
<a class="reference internal" href="python_api.html#tensor_comprehensions.define" title="tensor_comprehensions.define"><code class="xref py py-func docutils literal notranslate"><span class="pre">define()</span></code></a> function.</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">group_normalization</span><span class="o">=</span><span class="s2">&quot;&quot;&quot;...&quot;&quot;&quot;</span>
<span class="n">N</span><span class="p">,</span> <span class="n">G</span><span class="p">,</span> <span class="n">D</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">56</span><span class="p">,</span> <span class="mi">56</span>
<span class="n">T</span> <span class="o">=</span> <span class="n">tc</span><span class="o">.</span><span class="n">define</span><span class="p">(</span>
    <span class="n">group_normalization</span><span class="p">,</span>
    <span class="n">tc</span><span class="o">.</span><span class="n">make_autotuned_options_factory</span><span class="p">(</span>
        <span class="n">starting_options</span><span class="o">=</span><span class="s1">&#39;naive&#39;</span><span class="p">,</span>
        <span class="n">tuner_config</span><span class="o">=</span><span class="n">tuner_config</span><span class="p">))</span>
<span class="n">I</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">beta</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">G</span><span class="p">,</span> <span class="n">D</span><span class="p">,</span> <span class="n">H</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda&#39;</span><span class="p">),</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">D</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda&#39;</span><span class="p">),</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">D</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda&#39;</span><span class="p">))</span>
<span class="n">Sum</span><span class="p">,</span> <span class="n">SumSq</span><span class="p">,</span> <span class="n">O</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">group_normalization</span><span class="p">(</span><span class="n">I</span><span class="p">,</span> <span class="n">gamma</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">A tuning run can be aborted by sending the SIGINT signal (Ctrl+C). In
that case, the compilation and evaluation jobs currently in flight will
be flushed, but no new compilation job will be created. Once the jobs in
flight are flushed, saving to cache occurs (if requested) and the best
<a class="reference internal" href="python_api.html#tensor_comprehensions.tclib.MappingOptions" title="tensor_comprehensions.tclib.MappingOptions"><code class="xref py py-class docutils literal notranslate"><span class="pre">MappingOptions</span></code></a> found so far will be returned.</p>
</div>
</div></blockquote>
<p>Tuning behavior can be modified by defining the TC with an optional
<a class="reference internal" href="python_api.html#tensor_comprehensions.tclib.TunerConfig" title="tensor_comprehensions.tclib.TunerConfig"><code class="xref py py-class docutils literal notranslate"><span class="pre">TunerConfig</span></code></a> parameter constructed as such:
<code class="code docutils literal notranslate"><span class="pre">tuner_config=tc.TunerConfig().threads(5).generations(3).pop_size(5)</span></code>.</p>
<blockquote>
<div><div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">By providing a fixed filename and calling short tuning runs over
multiple executions with load_from_cache=True and store_to_cache=True,
one can effectively reinforce the tuning process over time without
paying a longer startup cost.</p>
</div>
</div></blockquote>
</div>
<div class="section" id="fixed-tc-varying-input-sizes">
<h2>Fixed TC, varying input sizes<a class="headerlink" href="#fixed-tc-varying-input-sizes" title="Permalink to this headline">¶</a></h2>
<p>A TC definition can be reused but will trigger recompilation for different size
combinations. While we recommend tuning independently for each TC and input size
variation, the best options found for a particular TC and input size
combination may transfer well to another input size (especially if
sizes are close and the kernels exhibit the same type of bottlenecs;
i.e. memory-bound, latency-bound, instruction-issue-bound,
compute-bound).</p>
</div>
<div class="section" id="pseudo-templating">
<h2>Pseudo-templating<a class="headerlink" href="#pseudo-templating" title="Permalink to this headline">¶</a></h2>
<p>The TC mapper requires statically affine tensor indexing functions.
Without getting into deeper details, the dependence analysis process is
significantly simplified and can be represented exactly.
As a consequence, tensor subscripts should avoid multiplications
between an unknown parametric quantity and an index variable.
In practice this may require writing different TC versions for different stride
and kernel sizes. A simple workaround would be for TC language to provide a
templating mechanism.
A much simpler way to achieve the same effect is to dynamically perform string
substitutions based on runtime values by formatting the TC string with python
regular expressions:</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">tensor_comprehensions</span> <span class="kn">as</span> <span class="nn">tc</span>
<span class="n">tc_str</span><span class="o">=</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">def avgpool(float(B, C, H, W) input) -&gt; (output) {</span>
<span class="s2">    output(b, c, h, w) +=! input(b, c, h * &lt;sH&gt; + r_kh, w * &lt;sW&gt; + r_kw) / (&lt;kH&gt; * &lt;kW&gt;)</span>
<span class="s2">        where r_kh in 0:&lt;kH&gt;, r_kw in 0:&lt;kW&gt;</span>
<span class="s2">}</span>
<span class="s2">&quot;&quot;&quot;</span>
<span class="n">tc_str</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s1">&#39;&lt;sh&gt;&#39;</span><span class="p">,</span> <span class="s1">&#39;1&#39;</span><span class="p">,</span> <span class="n">tc_str</span><span class="p">)</span>
<span class="n">tc_str</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s1">&#39;&lt;sw&gt;&#39;</span><span class="p">,</span> <span class="s1">&#39;1&#39;</span><span class="p">,</span> <span class="n">tc_str</span><span class="p">)</span>
<span class="n">tc_str</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s1">&#39;&lt;kH&gt;&#39;</span><span class="p">,</span> <span class="s1">&#39;2&#39;</span><span class="p">,</span> <span class="n">tc_str</span><span class="p">)</span>
<span class="n">tc_str</span> <span class="o">=</span> <span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s1">&#39;&lt;kW&gt;&#39;</span><span class="p">,</span> <span class="s1">&#39;3&#39;</span><span class="p">,</span> <span class="n">tc_str</span><span class="p">)</span>
<span class="n">T</span> <span class="o">=</span> <span class="n">tc</span><span class="o">.</span><span class="n">define</span><span class="p">(</span><span class="n">tc_str</span><span class="p">,</span> <span class="n">tc</span><span class="o">.</span><span class="n">make_naive_options_factory</span><span class="p">())</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">avgpool</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div></blockquote>
</div>
<div class="section" id="built-in-functions">
<h2>Built-in Functions<a class="headerlink" href="#built-in-functions" title="Permalink to this headline">¶</a></h2>
<p>TC allows using CUDA built-in functions as well when defining the TC operations.
During execution, the CUDA API will be called for those built-in
functions. For example, assume one wants to use <code class="code docutils literal notranslate"><span class="pre">fmax</span></code> CUDA function in TC:</p>
<blockquote>
<div><div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">tensor_comprehensions</span> <span class="kn">as</span> <span class="nn">tc</span>
<span class="n">tc_str</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">def relu(float(B,M) I) -&gt; (O) {</span>
<span class="s2">    O(b, m) = fmax(I(b, m), 0)</span>
<span class="s2">}</span>
<span class="s2">&quot;&quot;&quot;</span>
<span class="n">T</span> <span class="o">=</span> <span class="n">tc</span><span class="o">.</span><span class="n">define</span><span class="p">(</span><span class="n">tc_str</span><span class="p">,</span> <span class="n">tc</span><span class="o">.</span><span class="n">make_naive_options_factory</span><span class="p">())</span>
<span class="n">O</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="s1">&#39;cuda&#39;</span><span class="p">))</span>
</pre></div>
</div>
</div></blockquote>
<p>TC only supports a subset of built-in CUDA functions.
Built-in functions supported in TC are listed in <a class="reference external" href="https://github.com/facebookresearch/TensorComprehensions/blob/master/tc/core/libraries.h#L67">this file</a>.
Documentation
for these functions is available as part of the official <a class="reference external" href="http://docs.nvidia.com/cuda/cuda-math-api/group__CUDA__MATH__SINGLE.html#group__CUDA__MATH__SINGLE">CUDA documentation</a>.</p>
</div>
<div class="section" id="more-examples">
<h2>More examples<a class="headerlink" href="#more-examples" title="Permalink to this headline">¶</a></h2>
<p>You can find more examples in our <a class="reference external" href="https://github.com/facebookresearch/TensorComprehensions/blob/master/python/tests/test_tc.py">unit tests</a>.
We also provide more elaborate examples on how to <a class="reference external" href="https://github.com/facebookresearch/TensorComprehensions/blob/master/python/examples/min_distance.py#L151">compute argmin</a> as well as a simple TC + PyTorch <a class="reference external" href="https://github.com/facebookresearch/TensorComprehensions/blob/master/python/benchmarks/python_overhead.py">python overhead benchmark</a>.</p>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="autograd_with_tc.html" class="btn btn-neutral float-right" title="Autograd with TC" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="python_api.html" class="btn btn-neutral" title="Python API" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2017-present, Facebook, Inc..

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'../../',
            VERSION:'v0.1.1',
            LANGUAGE:'None',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="../../_static/jquery.js"></script>
      <script type="text/javascript" src="../../_static/underscore.js"></script>
      <script type="text/javascript" src="../../_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  <script type="text/javascript" src="../../_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>