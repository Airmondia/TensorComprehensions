

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>What is Tensor Comprehensions? &mdash; Tensor Comprehensions v0.1.1 documentation</title>
  

  
  
  
  

  

  
  
    

  

  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/tc_theme.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Semantics" href="semantics.html" />
    <link rel="prev" title="Tensor Comprehensions documentation" href="index.html" /> 

  
  <script src="_static/js/modernizr.min.js"></script>

</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search">
          

          
            <a href="index.html">
          

          
            
            <img src="_static/tc-logo-full-color-with-text-2.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
              <div class="version">
                v0.1.1
              </div>
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Index</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">What is Tensor Comprehensions?</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#example-of-using-tc-with-framework">Example of using TC with framework</a></li>
<li class="toctree-l2"><a class="reference internal" href="#tensor-comprehension-notation">Tensor Comprehension Notation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#examples-of-tc">Examples of TC</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#simple-matrix-vector">Simple matrix-vector</a></li>
<li class="toctree-l3"><a class="reference internal" href="#simple-2-d-convolution-no-stride-no-padding">Simple 2-D convolution (no stride, no padding)</a></li>
<li class="toctree-l3"><a class="reference internal" href="#simple-2d-max-pooling">Simple 2D max pooling</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="semantics.html">Semantics</a><ul>
<li class="toctree-l2"><a class="reference internal" href="semantics.html#types">Types</a></li>
<li class="toctree-l2"><a class="reference internal" href="semantics.html#data-layout">Data Layout</a></li>
<li class="toctree-l2"><a class="reference internal" href="semantics.html#variable-scoping">Variable Scoping</a></li>
<li class="toctree-l2"><a class="reference internal" href="semantics.html#implied-reductions-and-operators">Implied Reductions and operators</a></li>
<li class="toctree-l2"><a class="reference internal" href="semantics.html#size-expressions">Size Expressions</a></li>
<li class="toctree-l2"><a class="reference internal" href="semantics.html#statements">Statements</a></li>
<li class="toctree-l2"><a class="reference internal" href="semantics.html#expressions">Expressions</a></li>
<li class="toctree-l2"><a class="reference internal" href="semantics.html#grammar">Grammar</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="inference.html">Range Inference</a><ul>
<li class="toctree-l2"><a class="reference internal" href="inference.html#the-range-inference-algorithm">The Range Inference Algorithm</a></li>
<li class="toctree-l2"><a class="reference internal" href="inference.html#preconditions">Preconditions</a></li>
<li class="toctree-l2"><a class="reference internal" href="inference.html#worked-examples">Worked Examples</a><ul>
<li class="toctree-l3"><a class="reference internal" href="inference.html#inverted-indexing">Inverted indexing</a></li>
<li class="toctree-l3"><a class="reference internal" href="inference.html#strided-indexing-with-constant-stride">Strided indexing with constant stride</a></li>
<li class="toctree-l3"><a class="reference internal" href="inference.html#strided-indexing-with-offsets">Strided indexing with offsets</a></li>
<li class="toctree-l3"><a class="reference internal" href="inference.html#strided-indexing-with-dynamic-stride">Strided indexing with dynamic stride</a></li>
<li class="toctree-l3"><a class="reference internal" href="inference.html#constant-fill-using-an-exists-clause">Constant fill using an exists clause</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="halide_integration.html">Relation to Halide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="halide_integration.html#use-of-halide-in-tc">Use of Halide in TC</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="mapping_options.html">Mapping Options</a><ul>
<li class="toctree-l2"><a class="reference internal" href="mapping_options.html#how-to-choose-starting-mapping-options">How to choose starting mapping options?</a></li>
<li class="toctree-l2"><a class="reference internal" href="mapping_options.html#options-api">Options API</a></li>
<li class="toctree-l2"><a class="reference internal" href="mapping_options.html#defaults-provided">Defaults provided</a></li>
<li class="toctree-l2"><a class="reference internal" href="mapping_options.html#available-options">Available options</a></li>
<li class="toctree-l2"><a class="reference internal" href="mapping_options.html#impact-on-performance">Impact on Performance</a></li>
<li class="toctree-l2"><a class="reference internal" href="mapping_options.html#possible-compiler-issues">Possible compiler issues</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="autotuner.html">Autotuner</a><ul>
<li class="toctree-l2"><a class="reference internal" href="autotuner.html#parameters-for-autotuning">Parameters for Autotuning</a></li>
<li class="toctree-l2"><a class="reference internal" href="autotuner.html#caching">Caching</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="performance.html">Performance of TC</a></li>
</ul>
<p class="caption"><span class="caption-text">Machine Learning with TC</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="ml_with_tc.html">Positioning of TC in ML Software stacks</a><ul>
<li class="toctree-l2"><a class="reference internal" href="ml_with_tc.html#implications-of-ml-framework-integration">Implications of ML Framework Integration</a><ul>
<li class="toctree-l3"><a class="reference internal" href="ml_with_tc.html#one-tc-function-one-kernel">One TC function one kernel</a></li>
<li class="toctree-l3"><a class="reference internal" href="ml_with_tc.html#no-variable-allocations">No Variable Allocations</a></li>
<li class="toctree-l3"><a class="reference internal" href="ml_with_tc.html#graph-level">Graph Level</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="ml_with_tc.html#minimal-information-to-write-ml-layers-concisely">Minimal information to write ML layers concisely</a><ul>
<li class="toctree-l3"><a class="reference internal" href="ml_with_tc.html#c-style-loops">C-style loops</a></li>
<li class="toctree-l3"><a class="reference internal" href="ml_with_tc.html#halide">Halide</a></li>
<li class="toctree-l3"><a class="reference internal" href="ml_with_tc.html#tc">TC</a></li>
<li class="toctree-l3"><a class="reference internal" href="ml_with_tc.html#matrix-languages">Matrix Languages</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="integrating_any_ml_framework.html">Integrating TC with ML framework</a><ul>
<li class="toctree-l2"><a class="reference internal" href="integrating_any_ml_framework.html#step-1-dlpack-support-in-framework">Step 1: DLpack support in framework</a></li>
<li class="toctree-l2"><a class="reference internal" href="integrating_any_ml_framework.html#step-2-integrating-tc">Step 2: Integrating TC</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="coding_conventions.html">Coding Conventions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="coding_conventions.html#use-indices-named-after-parameters">Use indices named after parameters</a></li>
<li class="toctree-l2"><a class="reference internal" href="coding_conventions.html#prefix-reduction-index-names-with-r">Prefix reduction index names with <code class="code docutils literal notranslate"><span class="pre">r_</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="coding_conventions.html#filter-non-rectangular-regions-with-data-dependencies">Filter non-rectangular regions with data-dependencies</a></li>
<li class="toctree-l2"><a class="reference internal" href="coding_conventions.html#prefix-gradient-tensors-names-with-d">Prefix gradient tensors names with <code class="code docutils literal notranslate"><span class="pre">d_</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="coding_conventions.html#a-more-complex-example">A more complex example</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">PyTorch Integration</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="framework/pytorch_integration/getting_started.html">Getting Started</a><ul>
<li class="toctree-l2"><a class="reference internal" href="framework/pytorch_integration/getting_started.html#installation">Installation</a></li>
<li class="toctree-l2"><a class="reference internal" href="framework/pytorch_integration/getting_started.html#example">Example</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="framework/pytorch_integration/python_api.html">Python API</a><ul>
<li class="toctree-l2"><a class="reference internal" href="framework/pytorch_integration/python_api.html#high-level-api">High-level API</a></li>
<li class="toctree-l2"><a class="reference internal" href="framework/pytorch_integration/python_api.html#low-level-api">Low-level API</a></li>
<li class="toctree-l2"><a class="reference internal" href="framework/pytorch_integration/python_api.html#caching-and-configuration">Caching and Configuration</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="framework/pytorch_integration/writing_layers.html">Writing TC operations</a><ul>
<li class="toctree-l2"><a class="reference internal" href="framework/pytorch_integration/writing_layers.html#example">Example</a></li>
<li class="toctree-l2"><a class="reference internal" href="framework/pytorch_integration/writing_layers.html#specifying-mappingoptions">Specifying MappingOptions</a></li>
<li class="toctree-l2"><a class="reference internal" href="framework/pytorch_integration/writing_layers.html#loading-from-cache">Loading from cache</a></li>
<li class="toctree-l2"><a class="reference internal" href="framework/pytorch_integration/writing_layers.html#autotuning">Autotuning</a></li>
<li class="toctree-l2"><a class="reference internal" href="framework/pytorch_integration/writing_layers.html#fixed-tc-varying-input-sizes">Fixed TC, varying input sizes</a></li>
<li class="toctree-l2"><a class="reference internal" href="framework/pytorch_integration/writing_layers.html#pseudo-templating">Pseudo-templating</a></li>
<li class="toctree-l2"><a class="reference internal" href="framework/pytorch_integration/writing_layers.html#built-in-functions">Built-in Functions</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="framework/pytorch_integration/autograd_with_tc.html">Autograd with TC</a></li>
<li class="toctree-l1"><a class="reference internal" href="framework/pytorch_integration/debugging.html">Debugging</a><ul>
<li class="toctree-l2"><a class="reference internal" href="framework/pytorch_integration/debugging.html#example-usage">Example usage</a></li>
<li class="toctree-l2"><a class="reference internal" href="framework/pytorch_integration/debugging.html#printing-tc-generated-cuda-code">Printing TC generated CUDA code</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="framework/pytorch_integration/frequently_asked_questions.html">Frequently Asked Questions</a><ul>
<li class="toctree-l2"><a class="reference internal" href="framework/pytorch_integration/frequently_asked_questions.html#tc-language">TC language</a><ul>
<li class="toctree-l3"><a class="reference internal" href="framework/pytorch_integration/frequently_asked_questions.html#how-are-temporary-variables-handled-in-tc">How are temporary variables handled in TC?</a></li>
<li class="toctree-l3"><a class="reference internal" href="framework/pytorch_integration/frequently_asked_questions.html#can-i-re-use-a-temporary-variable">Can I re-use a temporary variable?</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="framework/pytorch_integration/frequently_asked_questions.html#autotuner">Autotuner</a><ul>
<li class="toctree-l3"><a class="reference internal" href="framework/pytorch_integration/frequently_asked_questions.html#at-the-start-of-a-new-generation-i-see-higher-kernel-runtimes-why">At the start of a new generation, I see higher kernel runtimes, Why?</a></li>
<li class="toctree-l3"><a class="reference internal" href="framework/pytorch_integration/frequently_asked_questions.html#i-sometimes-see-fluctuations-in-the-best-kernel-time-why">I sometimes see fluctuations in the best kernel time, why?</a></li>
<li class="toctree-l3"><a class="reference internal" href="framework/pytorch_integration/frequently_asked_questions.html#how-do-i-stop-autotuning-early-and-save-cache">How do I stop autotuning early and save cache?</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Installation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installation Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="installation.html#conda-installation">Conda installation</a></li>
<li class="toctree-l2"><a class="reference internal" href="installation.html#build-from-source">Build from source</a><ul>
<li class="toctree-l3"><a class="reference internal" href="installation.html#prerequisites">Prerequisites</a></li>
<li class="toctree-l3"><a class="reference internal" href="installation.html#conda-from-scratch-first-time-configuration">Conda from scratch (first time configuration)</a></li>
<li class="toctree-l3"><a class="reference internal" href="installation.html#activate-conda-in-your-current-terminal">Activate conda in your current terminal</a></li>
<li class="toctree-l3"><a class="reference internal" href="installation.html#build-tc-with-dependencies-supplied-by-conda">Build TC with dependencies supplied by conda</a></li>
<li class="toctree-l3"><a class="reference internal" href="installation.html#test-locally">Test locally</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="installation.html#advanced-development-mode-installation">Advanced / development mode installation</a><ul>
<li class="toctree-l3"><a class="reference internal" href="installation.html#optional-dependencies">Optional dependencies</a></li>
<li class="toctree-l3"><a class="reference internal" href="installation.html#cudnn-version-7-1-in-caffe2-dev-mode">Cudnn version 7.1 in Caffe2 / dev mode</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="installation_colab_research.html">Installation in the Google Colaboratory environment</a><ul>
<li class="toctree-l2"><a class="reference internal" href="installation_colab_research.html#step-1-create-new-notebook-in-the-google-research-colaboratory">Step 1: Create new Notebook in the Google Research Colaboratory</a></li>
<li class="toctree-l2"><a class="reference internal" href="installation_colab_research.html#step-2-create-a-new-code-cell-with-the-following-code">Step 2: Create a new Code Cell, with the following code</a></li>
<li class="toctree-l2"><a class="reference internal" href="installation_colab_research.html#step-3-use-tc-normally-from-python-torch-environment">Step 3: Use TC normally, from Python/Torch environment</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Paper</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="report.html">Tech Report</a></li>
</ul>
<p class="caption"><span class="caption-text">Support</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="contacts.html">Contacts</a><ul>
<li class="toctree-l2"><a class="reference internal" href="contacts.html#bugs-and-features">Bugs and features</a></li>
<li class="toctree-l2"><a class="reference internal" href="contacts.html#mailing-list">Mailing list</a></li>
<li class="toctree-l2"><a class="reference internal" href="contacts.html#contributions">Contributions</a></li>
<li class="toctree-l2"><a class="reference internal" href="contacts.html#slack-channel">Slack channel</a></li>
</ul>
</li>
</ul>
<p class="caption"><span class="caption-text">Tutorials Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="tutorials/index.html">Tensor Comprehensions Tutorials</a><ul>
<li class="toctree-l2"><a class="reference internal" href="tutorials/tutorial_tensordot_with_tc.html">Using TC to get fast CUDA code for TensorDot</a><ul>
<li class="toctree-l3"><a class="reference internal" href="tutorials/tutorial_tensordot_with_tc.html#about-tensordot">About TensorDot</a></li>
<li class="toctree-l3"><a class="reference internal" href="tutorials/tutorial_tensordot_with_tc.html#step-1-write-tc-for-tensordot">Step 1: Write TC for TensorDot</a></li>
<li class="toctree-l3"><a class="reference internal" href="tutorials/tutorial_tensordot_with_tc.html#step-2-register-operation-with-tc">Step 2: Register operation with TC</a></li>
<li class="toctree-l3"><a class="reference internal" href="tutorials/tutorial_tensordot_with_tc.html#step-3-create-input-tensors-and-run-tc">Step 3: Create input tensors and run TC</a></li>
<li class="toctree-l3"><a class="reference internal" href="tutorials/tutorial_tensordot_with_tc.html#step-4-autotune-and-get-better-performing-kernel">Step 4: Autotune and get better performing kernel</a></li>
<li class="toctree-l3"><a class="reference internal" href="tutorials/tutorial_tensordot_with_tc.html#early-stopping">Early stopping</a></li>
<li class="toctree-l3"><a class="reference internal" href="tutorials/tutorial_tensordot_with_tc.html#summary">Summary</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">Tensor Comprehensions</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>What is Tensor Comprehensions?</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/introduction.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="what-is-tensor-comprehensions">
<h1>What is Tensor Comprehensions?<a class="headerlink" href="#what-is-tensor-comprehensions" title="Permalink to this headline">¶</a></h1>
<p>Tensor Comprehensions(TC) is a notation based on generalized Einstein notation
for computing on multi-dimensional arrays. TC greatly simplifies ML framework
implementations by providing a concise and powerful syntax which can be efficiently
translated to high-performance computation kernels, automatically.</p>
<div class="section" id="example-of-using-tc-with-framework">
<h2>Example of using TC with framework<a class="headerlink" href="#example-of-using-tc-with-framework" title="Permalink to this headline">¶</a></h2>
<p>TC is supported both in Python and C++ and we also provide lightweight integration
with PyTorch/Caffe2 frameworks.</p>
<p>An example of how using TC in PyTorch looks like:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">tensor_comprehensions</span> <span class="kn">as</span> <span class="nn">tc</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="n">lang</span> <span class="o">=</span> <span class="s2">&quot;&quot;&quot;</span>
<span class="s2">def matmul(float(M, K) A, float(K, N) B) -&gt; (C) {</span>
<span class="s2">    C(m, n) +=! A(m, r_k) * B(r_k, n)</span>
<span class="s2">}</span>
<span class="s2">&quot;&quot;&quot;</span>
<span class="n">matmul</span> <span class="o">=</span> <span class="n">tc</span><span class="o">.</span><span class="n">define</span><span class="p">(</span><span class="n">lang</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;matmul&quot;</span><span class="p">)</span>
<span class="n">mat1</span><span class="p">,</span> <span class="n">mat2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">(),</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span><span class="o">.</span><span class="n">cuda</span><span class="p">()</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">matmul</span><span class="p">(</span><span class="n">mat1</span><span class="p">,</span> <span class="n">mat2</span><span class="p">)</span>
</pre></div>
</div>
<p>For more details on how to use TC with PyTorch, see <a class="reference internal" href="framework/pytorch_integration/getting_started.html#tc-with-pytorch"><span class="std std-ref">Getting Started</span></a>.</p>
<p>More generally the only requirement to integrate TC into a workflow is to use a
simple tensor library with a few basic functionalities. For more details, see
<a class="reference internal" href="integrating_any_ml_framework.html#integrating-ml-frameworks"><span class="std std-ref">Integrating TC with ML framework</span></a>.</p>
</div>
<div class="section" id="tensor-comprehension-notation">
<span id="tc-einstein-notation"></span><h2>Tensor Comprehension Notation<a class="headerlink" href="#tensor-comprehension-notation" title="Permalink to this headline">¶</a></h2>
<p>TC borrow three ideas from Einstein notation that make expressions concise:</p>
<ol class="arabic simple">
<li>loop index variables are defined implicitly by using them in an expression and their range is aggressively inferred based on what they index,</li>
<li>indices that appear on the right of an expression but not on the left are assumed to be reduction dimensions,</li>
<li>the evaluation order of points in the iteration space does not affect the output.</li>
</ol>
<p>Let’s start with a simple example is a matrix vector product:</p>
<div class="code highlight-default notranslate"><div class="highlight"><pre><span></span>def mv(float(R,C) A, float(C) x) -&gt; (o) {
    o(r) +=! A(r,r_c) * x(r_c)
}
</pre></div>
</div>
<p><code class="code docutils literal notranslate"><span class="pre">A</span></code> and <code class="code docutils literal notranslate"><span class="pre">x</span></code> are input tensors. <code class="code docutils literal notranslate"><span class="pre">o</span></code> is an output tensor.
The statement <code class="code docutils literal notranslate"><span class="pre">o(r)</span> <span class="pre">+=</span> <span class="pre">A(r,r_c)</span> <span class="pre">*</span> <span class="pre">x(r_c)</span></code> introduces two index variables <code class="code docutils literal notranslate"><span class="pre">r</span></code> and <code class="code docutils literal notranslate"><span class="pre">r_</span></code>.
Their range is inferred by their use indexing <code class="code docutils literal notranslate"><span class="pre">A</span></code> and <code class="code docutils literal notranslate"><span class="pre">x</span></code>. <code class="code docutils literal notranslate"><span class="pre">r</span> <span class="pre">=</span> <span class="pre">[0,R)</span></code>, <code class="code docutils literal notranslate"><span class="pre">r_c</span> <span class="pre">=</span> <span class="pre">[0,C)</span></code>.
Because <code class="code docutils literal notranslate"><span class="pre">r_c</span></code> only appears on the right side,
stores into <code class="code docutils literal notranslate"><span class="pre">o</span></code> will reduce over <code class="code docutils literal notranslate"><span class="pre">r_c</span></code> with the reduction specified for the loop.
Reductions can occur across multiple variables, but they all share the same kind of associative reduction (e.g. <code class="code docutils literal notranslate"><span class="pre">+=</span></code>)
to maintain invariant (3). Note that we prefix reduction indices names with
<code class="code docutils literal notranslate"><span class="pre">r_</span></code> for improved readability. <code class="code docutils literal notranslate"><span class="pre">mv</span></code> computes the same thing as this C++ loop:</p>
<div class="code highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span><span class="p">(</span><span class="nb">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">R</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
  <span class="n">o</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="o">=</span> <span class="mf">0.0</span><span class="n">f</span><span class="p">;</span>
  <span class="k">for</span><span class="p">(</span><span class="nb">int</span> <span class="n">j</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">j</span> <span class="o">&lt;</span> <span class="n">C</span><span class="p">;</span> <span class="n">j</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
    <span class="n">o</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="o">+=</span> <span class="n">A</span><span class="p">(</span><span class="n">i</span><span class="p">,</span><span class="n">j</span><span class="p">)</span> <span class="o">*</span> <span class="n">x</span><span class="p">(</span><span class="n">j</span><span class="p">);</span>
  <span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<p>The loop order <code class="code docutils literal notranslate"><span class="pre">[i,j]</span></code> here is arbitrarily chosen because the computed value of a TC is always independent of the loop order.</p>
</div>
<div class="section" id="examples-of-tc">
<h2>Examples of TC<a class="headerlink" href="#examples-of-tc" title="Permalink to this headline">¶</a></h2>
<p>We provide a few basic examples.</p>
<div class="section" id="simple-matrix-vector">
<h3>Simple matrix-vector<a class="headerlink" href="#simple-matrix-vector" title="Permalink to this headline">¶</a></h3>
<div class="code highlight-default notranslate"><div class="highlight"><pre><span></span>def mv(float(R,C) A, float(C) x) -&gt; (o) {
    o(r) +=! A(r,r_c) * x(r_c)
}
</pre></div>
</div>
</div>
<div class="section" id="simple-2-d-convolution-no-stride-no-padding">
<h3>Simple 2-D convolution (no stride, no padding)<a class="headerlink" href="#simple-2-d-convolution-no-stride-no-padding" title="Permalink to this headline">¶</a></h3>
<div class="code highlight-default notranslate"><div class="highlight"><pre><span></span>def conv(float(B,IP,H,W) input, float(OP,IP,KH,KW) weight) -&gt; (output) {
    output(b, op, h, w) +=! input(b, r_ip, h + r_kh, w + r_kw) * weight(op, r_ip, r_kh, r_kw)
}
</pre></div>
</div>
</div>
<div class="section" id="simple-2d-max-pooling">
<h3>Simple 2D max pooling<a class="headerlink" href="#simple-2d-max-pooling" title="Permalink to this headline">¶</a></h3>
<p>Note the similarity with a convolution with a “select”-style kernel:</p>
<div class="code highlight-default notranslate"><div class="highlight"><pre><span></span>def maxpool2x2(float(B,C,H,W) input) -&gt; (output) {
    output(b,c,h,w) max=! input(b,c,2*h + r_kw, 2*w + r_kh)
        where r_kw in 0:2, r_kh in 0..2
}
</pre></div>
</div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="semantics.html" class="btn btn-neutral float-right" title="Semantics" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="index.html" class="btn btn-neutral" title="Tensor Comprehensions documentation" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2017-present, Facebook, Inc..

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  

    <script type="text/javascript">
        var DOCUMENTATION_OPTIONS = {
            URL_ROOT:'./',
            VERSION:'v0.1.1',
            LANGUAGE:'None',
            COLLAPSE_INDEX:false,
            FILE_SUFFIX:'.html',
            HAS_SOURCE:  true,
            SOURCELINK_SUFFIX: '.txt'
        };
    </script>
      <script type="text/javascript" src="_static/jquery.js"></script>
      <script type="text/javascript" src="_static/underscore.js"></script>
      <script type="text/javascript" src="_static/doctools.js"></script>
      <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

  

  <script type="text/javascript" src="_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>